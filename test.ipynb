{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "# from keras.models import Sequential, load_model, model_from_config\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "# from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model[i])        \n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2word(x):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convertToVec(text):\n",
    "#     content=text\n",
    "#     if len(content) > 20:\n",
    "#         num_features = 300\n",
    "#         model = KeyedVectors.load_word2vec_format(\"word2vecmodel.bin\", binary=True)\n",
    "#         clean_test_essays = []\n",
    "#         clean_test_essays.append(sent2word(content))\n",
    "#         testDataVecs = getVecs(clean_test_essays, model, num_features )\n",
    "#         testDataVecs = np.array(testDataVecs)\n",
    "#         testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "\n",
    "#         lstm_model = load_model(\"final_lstm.h5\")\n",
    "#         preds = lstm_model.predict(testDataVecs)\n",
    "#         return str(round(preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToVec(text):\n",
    "    content=text\n",
    "    if len(content) > 20:\n",
    "        num_features = 300\n",
    "        model = KeyedVectors.load_word2vec_format(\"word2vecmodel.bin\", binary=True)\n",
    "        clean_test_essays = []\n",
    "        clean_test_essays.append(sent2word(content))\n",
    "        testDataVecs = getVecs(clean_test_essays, model, num_features )\n",
    "        testDataVecs = np.array(testDataVecs)\n",
    "        testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "\n",
    "        lstm_model = load_model(\"final_lstm.h5\")\n",
    "        bidirectional_model = load_model(\"final_bidirectional_lstm.h5\")\n",
    "        preds_lstm = lstm_model.predict(testDataVecs)\n",
    "        preds_bidirectional = bidirectional_model.predict(testDataVecs)\n",
    "        return [str(round(preds_lstm[0][0])),str(round(preds_bidirectional[0][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 537ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "final_text = \"I not agreed the people shuld d in the computer a lot and I going to said way. My first reason is because if you are a old man or your not going to d wit your kids and you going to have eyes problem so thas way you shuld in d in the computer a lot. My secon reason is the you going to have problem wit your wife if she found out the you are talking to another woman online because a lot of people they wife found out the they cant d wit other woman. My teard reason is the if you are a kid like me you not going to have fun and you not going to have friends because the computer problem came and go and not going to d wit your family and you lil sister out said playing wit her. So thas why you shulding d a lot in the computer.\"\n",
    "score = convertToVec(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '5']\n",
      "score predicted by lstm model 5\n",
      "score predicted by bidirectional model 5\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(\"score predicted by lstm model\",score[0])\n",
    "print(\"score predicted by bidirectional model\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "853ba7fe6af06eb3a0bba9c2d8f4c470d22bcce6bdc4592c396e33870ec7ee64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
